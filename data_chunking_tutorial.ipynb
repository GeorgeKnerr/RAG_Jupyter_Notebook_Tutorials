{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Chunking Lab: Text Splitting Strategies in LangChain\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this tutorial, we'll explore different text chunking strategies used in Retrieval-Augmented Generation (RAG) systems and Large Language Model (LLM) applications. Chunking is the process of breaking down large documents into smaller, manageable pieces that can be processed, embedded, and retrieved effectively.\n",
    "\n",
    "### Why is Chunking Important?\n",
    "\n",
    "- **Token Limits**: LLMs have context window limitations\n",
    "- **Retrieval Precision**: Smaller chunks allow for more precise semantic search\n",
    "- **Cost Efficiency**: Processing smaller chunks is more cost-effective\n",
    "- **Context Preservation**: Good chunking maintains semantic meaning\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "1. **Fixed-Size Chunking**: Simple character-based splitting\n",
    "2. **Recursive Character Chunking**: Intelligent context-preserving splitting\n",
    "3. **Sentence-Based Chunking**: Splitting by natural sentence boundaries\n",
    "4. **Semantic Chunking**: Splitting by paragraph/logical boundaries\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries\n",
    "\n",
    "We'll use LangChain's document loaders and text splitters, along with NLTK for sentence tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import nltk\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Download Required NLTK Data\n",
    "\n",
    "NLTK requires certain data files for tokenization. We'll download the required 'punkt' tokenizer data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ NLTK punkt tokenizer already available\n"
     ]
    }
   ],
   "source": [
    "# Download required NLTK data for sentence tokenization\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "    print(\"✅ NLTK punkt tokenizer already available\")\n",
    "except LookupError:\n",
    "    print(\"📥 Downloading NLTK punkt tokenizer...\")\n",
    "    nltk.download('punkt')\n",
    "    print(\"✅ NLTK punkt tokenizer downloaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load PDF Document\n",
    "\n",
    "We'll create a function to load and extract text from a PDF file using LangChain's PyMuPDFLoader. This loader automatically extracts text and creates document chunks that preserve page information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load and extract text from PDF\n",
    "def load_pdf_with_langchain(pdf_path):\n",
    "    \n",
    "    # Use LangChain's built-in loader\n",
    "    loader = PyMuPDFLoader(pdf_path)\n",
    "    \n",
    "    # Load the PDF into LangChain's document format\n",
    "    documents = loader.load()\n",
    "    \n",
    "    print(f\"Successfully loaded {len(documents)} document chunks from the PDF.\")\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Load Your Healthcare Document\n",
    "\n",
    "Now let's load an actual PDF document. Replace the path below with your own healthcare-related PDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 13 document chunks from the PDF.\n"
     ]
    }
   ],
   "source": [
    "# Path to the uploaded PDF (replace with your actual file path)\n",
    "pdf_path = \"./data/41598_2020_Article_64454.pdf\"\n",
    "\n",
    "# Extract the document chunks\n",
    "docs = load_pdf_with_langchain(pdf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Method 1: Fixed-Size Chunking\n",
    "\n",
    "## Understanding Fixed-Size Chunking\n",
    "\n",
    "Fixed-size chunking is the simplest approach where we break text into chunks based on a fixed number of characters. While simple and fast, it may cut off sentences halfway, potentially losing context.\n",
    "\n",
    "### Key Parameters:\n",
    "\n",
    "#### `chunk_size`\n",
    "The number of characters in each chunk.\n",
    "- **Example**: `chunk_size=500` creates chunks of 500 characters\n",
    "- Determines how much text is in each piece\n",
    "\n",
    "#### `chunk_overlap`\n",
    "The number of characters repeated between chunks to keep context.\n",
    "- **Example**: `chunk_overlap=50` means the last 50 characters of one chunk appear at the start of the next\n",
    "- Use overlap to avoid cutting off sentences or breaking flow across chunks\n",
    "- Helps maintain continuity and context between adjacent chunks\n",
    "\n",
    "### Pros and Cons:\n",
    "\n",
    "**Pros:**\n",
    "- ✅ Simple and fast\n",
    "- ✅ Predictable chunk sizes\n",
    "- ✅ Good for well-structured data\n",
    "\n",
    "**Cons:**\n",
    "- ❌ May cut sentences halfway\n",
    "- ❌ Can break logical flow\n",
    "- ❌ May confuse language models with incomplete thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Fixed Chunking in LangChain\n",
    "\n",
    "LangChain provides two main approaches to fixed-size text splitting:\n",
    "\n",
    "### 1. CharacterTextSplitter\n",
    "- Splits text into chunks based on a fixed number of characters\n",
    "- Uses a single separator (e.g., space `\" \"` or newline `\"\\n\"`)\n",
    "- If a sentence or paragraph is too long, it may split mid-sentence\n",
    "- **Best for**: Simple and fast splitting, but may not always preserve context cleanly\n",
    "\n",
    "### 2. RecursiveCharacterTextSplitter\n",
    "- Tries to split text at natural boundaries: paragraphs → sentences → words → characters\n",
    "- Uses a list of separators and recursively falls back if cleaner splits aren't possible\n",
    "- Produces better-structured chunks with less context loss\n",
    "- **More advanced**: Preserves semantic meaning better\n",
    "- **Recommended**: Use `RecursiveCharacterTextSplitter` when you want smart chunking, especially for documents with mixed formatting or longer sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total fixed-size chunks: 133\n",
      "\n",
      " Example:First Chunk \n",
      "1\n",
      "Scientific Reports | (2020) 10:7483 | https://doi.org/10.1038/s41598-020-64454-x\n",
      "www.nature.com/scientificreports\n",
      "Inhibitory action of \n",
      "phenothiazinium dyes against \n",
      "Neospora caninum\n",
      "Luiz Miguel Pereira1,2, Caroline Martins Mota   3, Luciana Baroni1, \n",
      "Cássia Mariana Bronzon da Costa1, Jade Cabestre Venancio Brochi1, Mark Wainwright4, \n",
      "Tiago Wilson Patriarca Mineo   3, Gilberto Úbida Leite Braga1 & Ana Patrícia Yatsuda1,2 ✉\n",
      "Neospora caninum is an Apicomplexan parasite related to important\n"
     ]
    }
   ],
   "source": [
    "# Define a function to split text into fixed-size character chunks using LangChain's CharacterTextSplitter.\n",
    "\n",
    "def fixed_size_chunking(docs, chunk_size=500, chunk_overlap=50):\n",
    "    \n",
    "    splitter = CharacterTextSplitter(\n",
    "        separator=\" \",\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    \n",
    "    return splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "# Apply it\n",
    "fixed_chunks = fixed_size_chunking(docs)\n",
    "print(f\" Total fixed-size chunks: {len(fixed_chunks)}\\n\")\n",
    "print(f\" Example:First Chunk \\n{fixed_chunks[0].page_content[:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total recursive chunks: 135\n",
      "\n",
      " Example: First Chunk \n",
      "1\n",
      "Scientific Reports |         (2020) 10:7483  | https://doi.org/10.1038/s41598-020-64454-x\n",
      "www.nature.com/scientificreports\n",
      "Inhibitory action of \n",
      "phenothiazinium dyes against \n",
      "Neospora caninum\n",
      "Luiz Miguel Pereira1,2, Caroline Martins Mota   3, Luciana Baroni1,  \n",
      "Cássia Mariana Bronzon da Costa1, Jade Cabestre Venancio Brochi1, Mark Wainwright4, \n",
      "Tiago Wilson Patriarca Mineo   3, Gilberto Úbida Leite Braga1 & Ana Patrícia Yatsuda1,2 ✉\n"
     ]
    }
   ],
   "source": [
    "# Splits documents using RecursiveCharacterTextSplitter which preserves context better\n",
    "\n",
    "def recursive_chunking(docs, chunk_size=500, chunk_overlap=50):\n",
    "    \n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    \n",
    "    return splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "# Apply it\n",
    "recursive_chunks = recursive_chunking(docs)\n",
    "print(f\" Total recursive chunks: {len(recursive_chunks)}\\n\")\n",
    "print(f\" Example: First Chunk \\n{recursive_chunks[0].page_content[:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 Observation: Fixed-Size Chunking\n",
    "\n",
    "### What We've Learned:\n",
    "\n",
    "1. **CharacterTextSplitter**:\n",
    "   - The `fixed_size_chunking()` function splits text based on a specific number of characters (e.g., 500)\n",
    "   - Simple and fast implementation\n",
    "   - **Limitation**: Does not respect sentence boundaries\n",
    "   - This means a chunk might start or end mid-sentence, which can confuse the language model\n",
    "\n",
    "2. **The Role of `chunk_overlap`**:\n",
    "   - Adding `chunk_overlap` (e.g., 50 characters) helps keep context between chunks\n",
    "   - The last 50 characters of one chunk appear at the start of the next\n",
    "   - This reduces information loss at chunk boundaries\n",
    "\n",
    "3. **RecursiveCharacterTextSplitter**:\n",
    "   - More intelligent than simple character splitting\n",
    "   - Attempts to split at natural boundaries (paragraphs, then sentences, then words)\n",
    "   - Produces cleaner, more contextually coherent chunks\n",
    "\n",
    "### When to Use Fixed-Size Chunking:\n",
    "- Quick setups or prototypes\n",
    "- Well-structured data where sentence cuts aren't a big issue\n",
    "- When processing speed is more important than perfect context preservation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Method 2: Sentence-Based Chunking\n",
    "\n",
    "## Understanding Sentence-Based Chunking\n",
    "\n",
    "Instead of splitting by character count, sentence-based chunking splits text into groups of complete sentences. This approach is more readable and retains better semantic meaning.\n",
    "\n",
    "### Key Parameter:\n",
    "\n",
    "#### `sentences_per_chunk`\n",
    "- Defines how many sentences to include in each chunk\n",
    "- **Example**: `sentences_per_chunk=3` will group 3 sentences together as one chunk\n",
    "- Each chunk is a complete thought or mini-paragraph\n",
    "\n",
    "### Why Use Sentence-Based Chunking?\n",
    "\n",
    "**Advantages:**\n",
    "- ✅ Keeps chunks meaningful and readable\n",
    "- ✅ Respects natural language flow\n",
    "- ✅ Makes each chunk easier for the model to understand\n",
    "- ✅ Especially helpful when documents have clear sentence structures\n",
    "\n",
    "**Best For:**\n",
    "- Research papers\n",
    "- Articles\n",
    "- Long-form text where sentence flow matters\n",
    "\n",
    "### How It Works:\n",
    "1. Use NLTK's `sent_tokenize()` to split text into sentences\n",
    "2. Group sentences into chunks of N sentences\n",
    "3. Each chunk contains complete, grammatically correct sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total sentence-based chunks: 240\n",
      "\n",
      " Example:\n",
      "1\n",
      "Scientific Reports |         (2020) 10:7483  | https://doi.org/10.1038/s41598-020-64454-x\n",
      "www.nature.com/scientificreports\n",
      "Inhibitory action of \n",
      "phenothiazinium dyes against \n",
      "Neospora caninum\n",
      "Luiz Miguel Pereira1,2, Caroline Martins Mota   3, Luciana Baroni1,  \n",
      "Cássia Mariana Bronzon da Costa1, Jade Cabestre Venancio Brochi1, Mark Wainwright4, \n",
      "Tiago Wilson Patriarca Mineo   3, Gilberto Úbida Leite Braga1 & Ana Patrícia Yatsuda1,2 ✉\n",
      "Neospora caninum is an Apicomplexan parasite related to important losses in livestock, causing \n",
      "abortions and decreased fertility in affected cows. Several chemotherapeutic strategies have been \n",
      "developed for disease control; however, no commercial treatment is available. Among the candidate \n",
      "drugs against neosporosis, phenothiazinium dyes, offer a low cost-efficient approach to parasite \n",
      "control.\n"
     ]
    }
   ],
   "source": [
    "# Define a function to split each page into chunks of N sentences.\n",
    "\n",
    "def sentence_based_chunking(docs, sentences_per_chunk=3):\n",
    "    \n",
    "    chunks = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        sentences = sent_tokenize(doc.page_content)\n",
    "        for i in range(0, len(sentences), sentences_per_chunk):\n",
    "            chunk_text = \" \".join(sentences[i:i + sentences_per_chunk])\n",
    "            chunks.append(chunk_text)\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "\n",
    "sentence_chunks = sentence_based_chunking(docs)\n",
    "print(f\" Total sentence-based chunks: {len(sentence_chunks)}\\n\")\n",
    "print(f\" Example:\\n{sentence_chunks[0][:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 Observation: Sentence-Based Chunking\n",
    "\n",
    "### What We've Learned:\n",
    "\n",
    "1. **Natural Language Flow**:\n",
    "   - The `sentence_based_chunking()` function breaks text into chunks of a fixed number of sentences (e.g., 3)\n",
    "   - This method respects natural language flow\n",
    "   - Each chunk is easier for the model to understand because it contains complete thoughts\n",
    "\n",
    "2. **Context Preservation**:\n",
    "   - Unlike character-based chunking, sentences are never cut mid-way\n",
    "   - Each chunk represents a coherent unit of meaning\n",
    "   - Better for downstream tasks like question answering and summarization\n",
    "\n",
    "3. **Especially Helpful For**:\n",
    "   - Documents with clean sentence structures\n",
    "   - Academic papers and articles\n",
    "   - Content where maintaining grammatical integrity is important\n",
    "\n",
    "### Best Use Cases:\n",
    "- Research papers, articles, and long-form text where sentence flow matters\n",
    "- When you need chunks that are semantically complete\n",
    "- Documents with well-formed sentences and paragraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Method 3: Semantic Chunking\n",
    "\n",
    "## Understanding Semantic Chunking\n",
    "\n",
    "Semantic chunking takes the most intelligent approach by splitting content based on paragraph breaks or logical boundaries. This method helps preserve the meaning of each idea or concept.\n",
    "\n",
    "### How It Works:\n",
    "\n",
    "Instead of counting characters or sentences, semantic chunking looks for natural breaks in the document:\n",
    "- **Paragraph boundaries** (indicated by `\\n\\n` - two newlines)\n",
    "- **Section breaks**\n",
    "- **Logical topic changes**\n",
    "\n",
    "### Why Use Semantic Chunking?\n",
    "\n",
    "**Advantages:**\n",
    "- ✅ Preserves complete ideas and concepts\n",
    "- ✅ Each chunk represents a logical unit of information\n",
    "- ✅ Best for documents with clear structural formatting\n",
    "- ✅ Reduces context fragmentation\n",
    "- ✅ Ideal for embedding generation and semantic search\n",
    "\n",
    "**Best For:**\n",
    "- Structured PDFs (like research papers with clear paragraphs)\n",
    "- Reports with proper formatting\n",
    "- Documents where each paragraph discusses a distinct topic\n",
    "\n",
    "### Important Note:\n",
    "This method works best when the original text is **well-formatted with clear paragraph structure**. If the document has inconsistent formatting, you might get uneven chunk sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total semantic chunks: 13\n",
      "\n",
      " Example:\n",
      "1\n",
      "Scientific Reports |         (2020) 10:7483  | https://doi.org/10.1038/s41598-020-64454-x\n",
      "www.nature.com/scientificreports\n",
      "Inhibitory action of \n",
      "phenothiazinium dyes against \n",
      "Neospora caninum\n",
      "Luiz Miguel Pereira1,2, Caroline Martins Mota   3, Luciana Baroni1,  \n",
      "Cássia Mariana Bronzon da Costa1, Jade Cabestre Venancio Brochi1, Mark Wainwright4, \n",
      "Tiago Wilson Patriarca Mineo   3, Gilberto Úbida Leite Braga1 & Ana Patrícia Yatsuda1,2 ✉\n",
      "Neospora caninum is an Apicomplexan parasite related to important losses in livestock, causing \n",
      "abortions and decreased fertility in affected cows. Several chemotherapeutic strategies have been \n",
      "developed for disease control; however, no commercial treatment is available. Among the candidate \n",
      "drugs against neosporosis, phenothiazinium dyes, offer a low cost-efficient approach to parasite \n",
      "control. We report the anti-parasitic effects of the phenothiaziums Methylene Blue (MB), New \n",
      "Methylene Blue (NMB), 1,9–Dimethyl Methylene Blue (DMMB) and Toluidine Blue O (TBO) on N. \n",
      "caninum, using in vitro and in vivo models. The dyes inhibited parasite proliferation at nanomolar \n",
      "concentrations (0.019–1.83 μM) and a synergistic effect was achieved when Methylene Blue was \n",
      "combined with New Methylene Blue (Combination Index = 0.84). Moreover, the phenothiazinium dyes \n",
      "improved parasite clearance when combined with Pyrimethamine (Pyr). Combination of Methylene \n",
      "Blue + 1,9–Dimethyl Methylene Blue demonstrated superior efficacy compared to Pyrimethamine \n",
      "based counterparts in an in vivo model of infection. We also observed that Methylene Blue, New \n",
      "Methylene Blue and 1,9–Dimethyl Methylene Blue increased by 5000% the reactive oxygen species \n",
      "(ROS) levels in N. caninum tachyzoites. Phenothiazinium dyes represent an accessible group of \n",
      "candidates with the potential to compound future formulations for neosporosis control.\n",
      "Neospora caninum, an obligate intracellular protozoan, belongs to Apicomplexa phylum, such as Plasmodium \n",
      "spp and Toxoplasma gondii. It causes neosporosis, a disease strongly correlated to abortion and decreased fertility \n",
      "in cattle, costing billions of dollars worldwide1–3. There is no effective commercial treatment for neosporosis, \n",
      "despite the efforts of several chemotherapy-focused groups4–6. For example, Artemisinins7–10, Miltefosine11, plant \n",
      "extracts12–14, Diamidines15,16, Buparvaquone4,17, organometallic ruthenium complexes18, Thiazolides19,20 were \n",
      "evaluated in in vitro and in vivo models with encouraging results. Moreover, polyether ionophore antibiotics21, \n",
      "Triazinones22–24, bumped kinase inhibitors25 have also been tested in farm ruminants26.\n",
      "Based on the promising effects of Methylene Blue (MB) against Plasmodium spp, the etiologic agent of malaria, \n",
      "our group determined the efficacy of this molecule on N. caninum, either alone or combined with Pyrimethamine \n",
      "(Pyr)27. MB, a phenothiazinium dye, was the first synthetic drug described to cure a patient affected by malaria in \n",
      "the XIX century, pioneering work performed by Paul Ehrlich28,29. Indeed, MB was used against Plasmodium until \n",
      "the use of Chloroquine and other drugs (massively utilized after the Second World War), which lack some of the \n",
      "reversible MB side effects (blue urine and sclera)30,31. During the later 20th/early 21st Centuries, the intense use \n",
      "of Chloroquine, Artemisinin, and Pyrimethamine has led to proven cases of Plasmodium resistance, demanding \n",
      "novel therapeutic candidates32. Interestingly, no reports of Plasmodium resistance have been reported in exper-\n",
      "imental MB-based therapies, reviving the dye as an antimalarial drug33. Moreover, phenothiazinium dyes such \n",
      "as New Methylene blue and Toluidine Blue O also demonstrated antimicrobial properties34,35, inspiring us to test \n",
      "these compounds against N. caninum.\n",
      "Ehrlich’s brilliant observations, concerning Methylene Blue suggest that other phenothiazinium derivatives \n",
      "(New Methylene Blue, Toluidine Blue O, and 1,9-Dimethyl Methylene Blue) may also provide safe, low-cost \n",
      "1Faculdade de Ciências Farmacêuticas de Ribeirão Preto, Universidade de São Paulo, Av do Café, sn/n, 14040-903, \n",
      "Ribeirão Preto, SP, Brazil. 2Núcleo de Apoio à Pesquisa em Produtos Naturais e Sintéticos, Universidade de São \n",
      "Paulo, Ribeirão Preto, SP, Brazil. 3Department of Immunology, Institute of Biomedical Sciences, Federal University of \n",
      "Uberlândia, Uberlândia, Brazil. 4School of Pharmacy and Biomolecular Sciences, Liverpool John Moores University, \n",
      "Liverpool, L3 3AF, United Kingdom. ✉e-mail: ayatsuda@fcfrp.usp.br\n",
      "OPEN\n"
     ]
    }
   ],
   "source": [
    "# Define a function to split based on paragraph breaks (using two newlines)\n",
    "\n",
    "def semantic_chunking(docs):\n",
    "    \n",
    "    chunks = []\n",
    "    for doc in docs:\n",
    "        paragraphs = doc.page_content.split(\"\\n\\n\")\n",
    "        for para in paragraphs:\n",
    "            cleaned = para.strip()\n",
    "            if cleaned:\n",
    "                chunks.append(cleaned)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "semantic_chunks = semantic_chunking(docs)\n",
    "print(f\" Total semantic chunks: {len(semantic_chunks)}\\n\")\n",
    "print(f\" Example:\\n{semantic_chunks[0][:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 Observation: Semantic Chunking\n",
    "\n",
    "### What We've Learned:\n",
    "\n",
    "1. **Logical Boundaries**:\n",
    "   - Semantic chunking splits text at paragraph boundaries (double newlines `\\n\\n`)\n",
    "   - Each chunk represents a complete idea or concept\n",
    "   - This is the most \"natural\" way to split documents\n",
    "\n",
    "2. **Context Preservation**:\n",
    "   - Maintains the semantic integrity of each section\n",
    "   - Each chunk is a self-contained unit of meaning\n",
    "   - Minimal loss of context between chunks\n",
    "\n",
    "3. **When It Works Best**:\n",
    "   - Great when the original text is well-formatted with clear paragraph structure\n",
    "   - Ideal for structured PDFs or reports with proper formatting\n",
    "   - Perfect for research papers where each paragraph discusses a distinct topic\n",
    "\n",
    "4. **Limitations**:\n",
    "   - Requires documents to have consistent formatting\n",
    "   - May produce variable-sized chunks (some paragraphs are longer than others)\n",
    "   - Not ideal for poorly formatted documents\n",
    "\n",
    "### Best Use Cases:\n",
    "- Structured PDFs or reports with proper formatting (like research papers)\n",
    "- Documents where maintaining topic coherence is critical\n",
    "- When you need each chunk to represent a complete concept or idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Comparing All Methods\n",
    "\n",
    "## Side-by-Side Comparison\n",
    "\n",
    "Now let's compare how each method chunks the same document. We'll look at the chunk at index 6 to see the differences clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fixed-size chunk at index 6: \n",
      "against Plasmodium spp, the etiologic agent of malaria, \n",
      "our group determined the efficacy of this molecule on N. caninum, either alone or combined with Pyrimethamine \n",
      "(Pyr)27. MB, a phenothiazinium dye, was the first synthetic drug described to cure a patient affected by malaria in \n",
      "the XIX century, pioneering work performed by Paul Ehrlich28,29. Indeed, MB was used against Plasmodium until \n",
      "the use of Chloroquine and other drugs (massively utilized after the Second World War), which lack some\n",
      "\n",
      " Recursive chunk at index 6: \n",
      "our group determined the efficacy of this molecule on N. caninum, either alone or combined with Pyrimethamine \n",
      "(Pyr)27. MB, a phenothiazinium dye, was the first synthetic drug described to cure a patient affected by malaria in \n",
      "the XIX century, pioneering work performed by Paul Ehrlich28,29. Indeed, MB was used against Plasmodium until \n",
      "the use of Chloroquine and other drugs (massively utilized after the Second World War), which lack some of the\n",
      "\n",
      " Sentence-based chunk at index 6:\n",
      "Interestingly, no reports of Plasmodium resistance have been reported in exper-\n",
      "imental MB-based therapies, reviving the dye as an antimalarial drug33. Moreover, phenothiazinium dyes such \n",
      "as New Methylene blue and Toluidine Blue O also demonstrated antimicrobial properties34,35, inspiring us to test \n",
      "these compounds against N. caninum. Ehrlich’s brilliant observations, concerning Methylene Blue suggest that other phenothiazinium derivatives \n",
      "(New Methylene Blue, Toluidine Blue O, and 1,9-Dimethyl Methylene Blue) may also provide safe, low-cost \n",
      "1Faculdade de Ciências Farmacêuticas de Ribeirão Preto, Universidade de São Paulo, Av do Café, sn/n, 14040-903, \n",
      "Ribeirão Preto, SP, Brazil.\n",
      "\n",
      " Semantic chunk at index 6:\n",
      "7\n",
      "Scientific Reports |         (2020) 10:7483  | https://doi.org/10.1038/s41598-020-64454-x\n",
      "www.nature.com/scientificreports\n",
      "www.nature.com/scientificreports/\n",
      "Effects of phenothiazinium dyes in an in vivo model. \n",
      "The clearance assay is a more suitable method \n",
      "to guide a rational strategy for the treatment of neosporosis in animal models. The clearance assay reveals the \n",
      "elimination of parasites from cell culture, whereas proliferation measures the capacity of tachyzoite multiplication \n",
      "in the presence of the compound. Therefore, the in vitro clearance assay is similar to in vivo chemotherapy, since \n",
      "both methodologies are based on the parasite elimination from a host. Thus, mice infected with N. caninum were \n",
      "treated with DMMB alone or in combination with MB or Pyr, which demonstrated the highest in in vitro clear-\n",
      "ance rates (Fig. 3). TBO and NMB were excluded from the in vivo assays due to the higher SI compared to MB and \n",
      "DMMB and due to the lower clearance and mitochondria depolarization capacity, respectively. We based the in \n",
      "vivo parameters on articles that analyzed the effects of MB in models using mice36,51–53. MB was tested in different \n",
      "doses (2.5 to 2000 mg/Kg) with deleterious effects usually observed in long term treatments (five weeks) using \n",
      "doses >100 mg/Kg/day53. However, no studies have ever been performed for assessing the in vivo toxic effects of \n",
      "DMMB, demanding complementary toxicological assays. In a murine model of malaria, it was estimated that \n",
      "a regimen using MB 45.77 mg/Kg/day eliminates 90% of Plasmodium berghei36. Moreover, the effectiveness of \n",
      "intraperitoneal MB (50 and 100 mg/Kg/day) to control the blood stage of Plasmodium yoelii in BALB/c mice was \n",
      "also demonstrated54. Thus, for the initial treatment of animals acutely infected with N. caninum, a dose of 50 mg/\n",
      "Kg/day (MB and/or DMMB) represented a rational choice. We used cerebral neosporosis as a first approach once \n",
      "the main features of the compounds (mortality, morbidity, parasite burden, and toxicity) may be assessed before \n",
      "the use of more complex models.\n",
      "On the sixth day after N. caninum infection, 2 out of 6 animals treated with PBS died. Under treatment with \n",
      "DMMB 1 out of 6 died after the seventh and eighth days. The DMMB + Pyr combination demonstrated a sim-\n",
      "ilar result, with 2 animals succumbing after the eighth day. However, all animals (6/6) were protected by the \n",
      "combination of DMMB with MB (Fig. 6A) and no evident clinical signs (ruffled coat, apathy, walking disorders, \n",
      "rounded back and paralysis) were observed. Despite similar protection of animals treated with DMMB and the \n",
      "combination DMMB + Pyr, the cerebral parasite burden from the surviving animals was different. The ratio of \n",
      "parasite/host cell DNA in animals treated with DMMB and DMMB + Pyr combination was 4.43 and 0.95 respec-\n",
      "tively. The DMMB + MB combination reached 0.53, whereas for PBS control the relation was 2.56 (Fig. 6B). \n",
      "The combinations demonstrated superior efficacies compared to DMMB applied alone, elevating the surviving \n",
      "rate and/or decreasing the parasite burden. The efficacy of DMMB alone for the treatment of infected animals \n",
      "demonstrated the limitations of single-compound based chemotherapies. Drugs usually have few therapeutic \n",
      "targets, and this is usually insufficient against multiple evasion mechanisms in protozoans such as N. caninum \n",
      "or T. gondii55. Moreover, parasite resistance to Pyr has been achieved in N. caninum and T. gondii in culture56,57. \n",
      "Surprisingly, compounds from the same class (DMMB and MB) demonstrated superior performance compared \n",
      "Figure 4.  ROS production in tachyzoites and Vero cells incubated with MB, NMB, DMMB, and combinations. \n",
      "Tachyzoites (A,C) and Vero cells (B,D) were incubated with dilutions (4 × IC50) of NMB, MB, DMMB and its \n",
      "combinations (4 × IC50) for 30 min, 37 °C, 5% CO2. After the incubation, parasites or cells were washed with \n",
      "PBS and incubated with DCFDA (Sigma) for 15 min, 37 °C, 5% CO2 in the dark. Samples were analyzed in a BD \n",
      "FACS-Canto cytometer and the fluorescence intensity median achieved (A,B). The percentage of fluorescence \n",
      "was also calculated, compared to the no compound control (C,D). *p < 0.05.\n"
     ]
    }
   ],
   "source": [
    "fixed_chunks = fixed_size_chunking(docs)\n",
    "#print(f\" Total fixed-size chunks: {len(fixed_chunks)}\")\n",
    "print(f\" Fixed-size chunk at index 6: \\n{fixed_chunks[6].page_content[:]}\\n\")\n",
    "\n",
    "recursive_chunks = recursive_chunking(docs)\n",
    "#print(f\" Total recursive chunks: {len(recursive_chunks)}\")\n",
    "print(f\" Recursive chunk at index 6: \\n{recursive_chunks[6].page_content[:]}\\n\")\n",
    "\n",
    "sentence_chunks = sentence_based_chunking(docs)\n",
    "#print(f\" Total sentence-based chunks: {len(sentence_chunks)}\")\n",
    "print(f\" Sentence-based chunk at index 6:\\n{sentence_chunks[6][:]}\\n\")\n",
    "\n",
    "semantic_chunks = semantic_chunking(docs)\n",
    "#print(f\" Total semantic chunks: {len(semantic_chunks)}\")\n",
    "print(f\" Semantic chunk at index 6:\\n{semantic_chunks[6][:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Key Observations\n",
    "\n",
    "### What You'll Notice:\n",
    "\n",
    "If we look closely, we'll see that **the chunk at index 0 contains the same content across all the methods** (Fixed Chunking, Recursive Chunking, Sentence-Based Chunking, and Semantic Chunking).\n",
    "\n",
    "However, **when we invoke the chunk at index 6, the differences among the methods become clear**:\n",
    "\n",
    "1. **Fixed-Size Chunking (CharacterTextSplitter)**:\n",
    "   - May cut sentences mid-way\n",
    "   - Less readable and may lose context\n",
    "   - Fastest but least intelligent\n",
    "\n",
    "2. **Recursive Chunking (RecursiveCharacterTextSplitter)**:\n",
    "   - Tries to preserve natural boundaries\n",
    "   - Better context preservation than fixed-size\n",
    "   - Good balance of speed and quality\n",
    "\n",
    "3. **Sentence-Based Chunking**:\n",
    "   - Always contains complete sentences\n",
    "   - More readable and coherent\n",
    "   - Better for maintaining grammatical structure\n",
    "\n",
    "4. **Semantic Chunking**:\n",
    "   - Contains complete paragraphs or logical sections\n",
    "   - Best preserves the author's intended structure\n",
    "   - Most contextually coherent\n",
    "   - Ideal for downstream tasks like embedding generation\n",
    "\n",
    "### The Takeaway:\n",
    "While all methods may produce similar results for early chunks, their **structural differences become apparent** as you go deeper into the document. Choose your chunking method based on:\n",
    "- Your document's structure\n",
    "- Your downstream task requirements\n",
    "- The balance between speed and quality you need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 🎯 Hands-On Activity\n",
    "\n",
    "## Your Task:\n",
    "\n",
    "Given a healthcare-related article or PDF, use both `CharacterTextSplitter` and `RecursiveCharacterTextSplitter` from LangChain to chunk the text.\n",
    "\n",
    "**Requirements:**\n",
    "1. Allow the values for `chunk_size` and `chunk_overlap` to be set dynamically by the user\n",
    "2. Implement both chunking methods (CharacterTextSplitter and RecursiveCharacterTextSplitter) using the user-defined chunk_size and chunk_overlap\n",
    "3. Print and compare the first 3 chunks generated by each method\n",
    "4. Reflect on the differences in structure, readability, and context continuity between the two methods\n",
    "\n",
    "## What You Need to Do:\n",
    "\n",
    "1. **Implement both chunking methods** (`CharacterTextSplitter` and `RecursiveCharacterTextSplitter`) using the user-defined `chunk_size` and `chunk_overlap`\n",
    "\n",
    "2. **Print and compare the first 3 chunks** generated by each method\n",
    "\n",
    "3. **Reflect on the differences** in structure, readability, and context continuity between the two methods\n",
    "\n",
    "---\n",
    "\n",
    "## 🤔 Reflection Question:\n",
    "\n",
    "**Which chunking method better preserves the original structure and meaning of the content — and why might that be important for downstream tasks like embeddings, semantic retrieval, or LLM-based answer generation?**\n",
    "\n",
    "Consider:\n",
    "- How each method handles sentence boundaries\n",
    "- The impact on semantic coherence\n",
    "- Trade-offs between simplicity and context preservation\n",
    "- Which method would work best for your specific use case\n",
    "\n",
    "---\n",
    "\n",
    "## 💡 Tips for Your Implementation:\n",
    "\n",
    "1. Start with reasonable values like `chunk_size=500` and `chunk_overlap=50`\n",
    "2. Experiment with different values to see how they affect the output\n",
    "3. Pay attention to how sentences are split (or not split) in each method\n",
    "4. Consider the readability of each chunk\n",
    "\n",
    "Try it out in the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here!\n",
    "# TODO: Implement both CharacterTextSplitter and RecursiveCharacterTextSplitter\n",
    "# TODO: Compare the first 3 chunks from each method\n",
    "# TODO: Write your observations and reflection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 📚 Summary and Best Practices\n",
    "\n",
    "## Chunking Strategy Cheat Sheet:\n",
    "\n",
    "| Method | Best For | Pros | Cons |\n",
    "|--------|----------|------|------|\n",
    "| **Fixed-Size (CharacterTextSplitter)** | Quick prototypes, well-structured data | Fast, predictable | May cut sentences |\n",
    "| **Recursive (RecursiveCharacterTextSplitter)** | Most general use cases | Smart splitting, good balance | Slightly slower |\n",
    "| **Sentence-Based** | Clean text with clear sentences | Readable, grammatically correct | Requires sentence detection |\n",
    "| **Semantic (Paragraph-Based)** | Well-formatted documents | Preserves complete ideas | Needs structured input |\n",
    "\n",
    "## Key Takeaways:\n",
    "\n",
    "1. **Start with RecursiveCharacterTextSplitter** - It's a safe default for most use cases\n",
    "2. **Use chunk_overlap** - Helps maintain context across boundaries (typically 10-20% of chunk_size)\n",
    "3. **Consider your downstream task** - Embedding models and retrieval systems benefit from coherent chunks\n",
    "4. **Test and iterate** - What works for one document type may not work for another\n",
    "5. **Balance chunk size** - Too small loses context, too large may exceed token limits\n",
    "\n",
    "## Next Steps:\n",
    "\n",
    "- Experiment with different chunk sizes for your specific use case\n",
    "- Try combining methods (e.g., semantic chunking followed by size-based splitting)\n",
    "- Consider using more advanced techniques like embedding-based semantic chunking\n",
    "- Test how different chunking strategies affect your RAG system's performance\n",
    "\n",
    "Happy chunking! 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
